@article{minaee2024large,
  author = {S. Minaee and T. Mikolov and N. Nikzad and M. Chenaghlu and R. Socher and X. Amatriain and J. Gao},
  title = {Large Language Models: A Survey},
  journal = {arXiv preprint arXiv:2402.06196},
  year = {2024},
  month = {Feb},
  note = {Available: \url{https://arxiv.org/abs/2402.06196}}
}

@article{brown2023gpt4,
  author = {T. Brown et al.},
  title = {GPT-4 Technical Report},
  journal = {arXiv preprint arXiv:2303.08774},
  year = {2023},
  note = {Available: \url{https://arxiv.org/pdf/2303.08774}. [Accessed: 02-Apr-2025]}
}

@article{wang2023overview,
  author = {L. Wang and J. Li and Y. Zhang},
  title = {A Comprehensive Overview of Large Language Models},
  journal = {arXiv preprint arXiv:2307.06435},
  year = {2023},
  note = {Available: \url{https://arxiv.org/pdf/2307.06435}. [Accessed: 02-Apr-2025]}
}

@article{liu2025attention,
  author = {Q. Liu and X. Chen and Y. Ding and S. Xu and S. Wu and L. Wang},
  title = {Attention-Guided Self-Reflection for Zero-Shot Hallucination Detection in Large Language Models},
  journal = {arXiv preprint arXiv:2501.09997},
  year = {2025},
  month = {Jan}
}

@article{manakul2023selfcheckgpt,
  author = {P. Manakul and A. Liusie and M. J. F. Gales},
  title = {SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models},
  journal = {arXiv preprint arXiv:2303.08896},
  year = {2023},
  note = {Available: \url{http://arxiv.org/pdf/2303.08896}}
}

@article{varshney2023selfcritiquing,
  author = {N. Varshney and W. Yao and H. Zhang and J. Chen and D. Yu},
  title = {Detecting and mitigating hallucinations via self-critiquing},
  journal = {arXiv preprint arXiv:2307.03987},
  year = {2023},
  note = {Available: \url{https://arxiv.org/abs/2307.03987}}
}

@article{xu2024hallucination,
  author = {Z. Xu and S. Jain and M. Kankanhalli},
  title = {Hallucination is Inevitable: An Innate Limitation of Large Language Models},
  journal = {arXiv preprint arXiv:2401.11817},
  year = {2024},
  month = {Jan},
  note = {Available: \url{https://arxiv.org/pdf/2401.11817}}
}

@article{fu2024hallucination,
  author = {Y. Fu and X. Wang and J. Chen and M. Zhang},
  title = {On Large Language Models' Hallucination with Regard to Known Facts},
  journal = {arXiv preprint arXiv:2403.20009},
  year = {2024},
  month = {Mar},
  note = {Available: \url{https://arxiv.org/pdf/2403.20009v1}}
}

@article{simhi2025highcertainty,
  author = {A. Simhi and I. Itzhak and F. Barez and G. Stanovsky and Y. Belinkov},
  title = {Trust Me, I’m Wrong: High-Certainty Hallucinations in LLMs},
  journal = {arXiv preprint arXiv:2502.12964},
  year = {2025},
  note = {Available: \url{https://arxiv.org/pdf/2502.12964}}
}

@inproceedings{li2024dawn,
  author = {J. Li and Q. Dong and J. Liu and Z. Ma and W. Zhang},
  title = {The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models},
  booktitle = {Proc. 62nd Annual Meeting of the Association for Computational Linguistics (ACL)},
  year = {2024},
  pages = {10879--10899},
  address = {Bangkok, Thailand}
}

@article{varshney2023validating,
  author = {N. Varshney and W. Yao and H. Zhang and J. Chen and D. Yu},
  title = {A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation},
  journal = {arXiv preprint arXiv:2307.03987},
  year = {2023},
  note = {Available: \url{https://arxiv.org/abs/2307.03987}}
}

@article{denecke2024potential,
  author = {K. Denecke and R. May and LLMHealthGroup and O. Rivera Romero},
  title = {Potential of Large Language Models in Health Care: Delphi Study},
  journal = {Journal of Medical Internet Research},
  volume = {26},
  pages = {e52399},
  year = {2024},
  doi = {10.2196/52399}
}

@article{varshney2023hallucinations,
  author = {N. Varshney and W. Yao and H. Zhang and J. Chen and D. Yu},
  title = {Detecting and mitigating hallucinations via self-critiquing},
  journal = {arXiv preprint arXiv:2307.03987},
  year = {2023},
  note = {Available: \url{https://arxiv.org/abs/2307.03987}}
}

@article{wu2025evaluating,
  author = {X. Wu and J. Nian and Z. Tao and Y. Fang},
  title = {Evaluating Social Biases in LLM Reasoning},
  journal = {arXiv},
  year = {2025},
  note = {Available: \url{https://arxiv.org/pdf/2502.15361}. [Accessed: Mar. 30, 2025]}
}

@inproceedings{tang2024exploring,
  author = {J. Tang and Y. Tang and J. Yao},
  title = {Exploring Causal Effect of Social Bias on Faithfulness Hallucinations in Large Language Models},
  booktitle = {Proceedings of the 2024 International Conference on Learning Representations (ICLR)},
  year = {2024},
  note = {Available: \url{https://openreview.net/pdf?id=aOiUOohUBw}}
}

@article{zhu2024pollmgraph,
  author = {D. Zhu and D. Chen and Q. Li and Z. Chen and L. Ma and J. Grossklags and M. Fritz},
  title = {PoLLMgraph: Unraveling Hallucinations in Large Language Models via State Transition Dynamics},
  journal = {arXiv preprint arXiv:2404.04722},
  year = {2024},
  month = {Apr}
}

@article{gallegos2024selfdebiasing,
  author = {I. O. Gallegos and R. A. Rossi and J. Barrow and M. M. Tanjim and T. Yu and H. Deilamsalehy and R. Zhang and S. Kim and F. Dernoncourt},
  title = {Self-Debiasing Large Language Models: Zero-Shot Recognition and Reduction of Stereotypes},
  journal = {arXiv preprint arXiv:2402.01981},
  year = {2024},
  note = {Available: \url{https://arxiv.org/pdf/2402.01981}}
}

@article{may2019measuring,
  author = {C. May and A. Wang and S. Bordia and S. R. Bowman and R. Rudinger},
  title = {On Measuring Social Biases in Sentence Encoders},
  journal = {arXiv preprint arXiv:1903.10561},
  year = {2019}
}

@article{scherrer2023gender,
  author = {A. Scherrer and R. West},
  title = {Kelly is a Warm Person, Joseph is a Role Model: Gender Biases in LLM-Generated Reference Letters},
  journal = {arXiv preprint arXiv:2310.09219},
  year = {2023},
  note = {Available: \url{https://arxiv.org/pdf/2310.09219}}
}

@article{thong2020biasaware,
  author = {W. Thong and C. G. M. Snoek},
  title = {Bias-aware classifier for generalized zero-shot learning},
  journal = {arXiv preprint arXiv:2008.11185},
  year = {2020},
  note = {Available: \url{https://arxiv.org/abs/2008.11185}}
}

@article{anderson2024bias,
  author = {D. Anderson and M. D. Smith},
  title = {Inherent Bias in Large Language Models: A Random Sampling Approach},
  journal = {J. Digital Health},
  volume = {10},
  pages = {1--8},
  year = {2024}
}

@article{anantaprayoon2025intentaware,
  author = {P. Anantaprayoon and M. Kaneko and N. Okazaki},
  title = {Intent-Aware Self-Correction for Mitigating Social Biases in Large Language Models},
  journal = {arXiv preprint arXiv:2503.06011},
  year = {2025},
  month = {Mar},
  note = {Available: \url{https://arxiv.org/pdf/2503.06011}}
}

@article{pan2025beneath,
  author = {J. Pan and C. Raj and Z. Yao and Z. Zhu},
  title = {Beneath the Surface: How Large Language Models Reflect Hidden Bias},
  journal = {arXiv preprint arXiv:2502.19749},
  year = {2025},
  note = {Available: \url{https://arxiv.org/abs/2502.19749}}
}
@misc{truthfulqa2021,
  author       = {Stephanie Lin},
  title        = {TruthfulQA},
  year         = {2021},
  howpublished = {\url{https://github.com/sylinrl/TruthfulQA}},
  note         = {Accessed: 2025-04-18}
}
@article{lin2021truthfulqa,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2109.07958},
  year={2021},
  url={https://arxiv.org/abs/2109.07958}
}
@article{lambert2025reinforcement,
  author       = {Lambert, Nathan},
  title        = {Reinforcement Learning from Human Feedback},
  journal      = {arXiv preprint arXiv:2504.12501},
  year         = {2025},
  month        = {April},
  archivePrefix = {arXiv},
  eprint       = {2504.12501},
  primaryClass = {cs.LG}
}
@article{lobo2024impact,
  author = {E. Lobo and C. Agarwal and H. Lakkaraju},
  title = {On the impact of fine-tuning on chain-of-thought reasoning},
  journal = {arXiv preprint arXiv:2411.15382},
  year = {2024},
  month = {Nov},
  url = {https://arxiv.org/pdf/2411.15382}
}
@inproceedings{pan2023risk,
  title={On the Risk of Misinformation Pollution with Large Language Models},
  author={Pan, Yuxuan and Pan, Liang and Chen, Wenhu and Nakov, Preslav and Kan, Min-Yen and Wang, William Yang},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={1389--1403},
  year={2023},
  address={Singapore},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2023.findings-emnlp.97}
}
@article{xie2024gradsafe,
  title={GradSafe: Detecting Jailbreak Prompts for LLMs via Safety-Critical Gradient Analysis},
  author={Xie, Yuxin and Fang, Mengzhou and Pi, Renyu and Gong, Neil Zhenqiang},
  journal={arXiv preprint arXiv:2402.13494},
  year={2024}
}
@article{liu2024towards,
  title={Towards Safer Large Language Models through Machine Unlearning},
  author={Liu, Zifan and Dou, Guangyuan and Tan, Zhiyuan and Tian, Yuan and Jiang, Meng},
  journal={arXiv preprint arXiv:2402.10058},
  year={2024},
  month={Feb}
}
@article{ranjan2024bias,
  title={A Comprehensive Survey of Bias in LLMs: Current Landscape and Future Directions},
  author={Ranjan, Ritam and Gupta, Saket and Singh, Santanu Narayan},
  journal={arXiv preprint arXiv:2409.16430},
  year={2024},
  month={sep},
}@article{parthasarathy2024ultimateguide,
  author = {V. B. Parthasarathy and A. Zafar and A. Khan and A. Shahid},
  title = {The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities},
  journal = {arXiv preprint arXiv:2408.13296v1},
  year = {2024},
  month = {Aug},
  note = {Available at: \url{https://arxiv.org/abs/2408.13296v1}}
}
@article{chen2024editable,
  title={Editable Fairness: Fine-Grained Bias Mitigation in Language Models},
  author={Chen, R. and Li, Y. and Yang, J. T. and Zhou, J. T. and Liu, Z.},
  journal={arXiv preprint arXiv:2408.11843},
  year={2024},
  month={Aug},
  url={https://arxiv.org/abs/2408.11843}
}
@article{li2023survey,
  title={A Survey on Fairness in Large Language Models},
  author={Li, Yingji and Du, Mengnan and Song, Rui and Wang, Xin and Wang, Ying},
  journal={arXiv preprint arXiv:2308.10149},
  year={2023},
  month={August}
}
@article{liang2024learning,
  title={Learning to Trust Your Feelings: Leveraging Self-awareness in LLMs for Hallucination Mitigation},
  author={Liang, Yuxin and Song, Zhuoyang and Wang, Hao and Zhang, Jiaxing},
  journal={arXiv preprint arXiv:2401.15449},
  year={2024},
  month={January}
}
@article{gallegos2024bias,
  author = {Gallegos, Isabel O. and Rossi, Ryan A. and Barrow, Joe and Tanjim, Md Mehrab and Kim, Sungchul and Dernoncourt, Franck and Yu, Tong and Zhang, Ruiyi and Ahmed, Nesreen K.},
  journal = {Computational Linguistics},
  title = {Bias and fairness in large language models: A survey},
  volume = {50},
  number = {3},
  pages = {1--28},
  year = {2024},
  month = {Jul},
  note = {Accepted for publication},
  url = {https://arxiv.org/abs/2309.00770}
}
@article{liu2024prejudice,
  title={Prejudice and Volatility: A Statistical Framework for Measuring Social Discrimination in Large Language Models},
  author={Liu, Yiran and Yang, Kaijie and Qi, Zeyu and Liu, Xiaozhong and Yu, Yizhou and Zhai, ChengXiang},
  journal={arXiv preprint arXiv:2402.15481},
  year={2024},
  month={Feb},
  url={https://arxiv.org/abs/2402.15481}
}
@article{wan2023gender,
  author = {Y. Wan and G. Pu and J. Sun and A. Garimella and K.-W. Chang and N. Peng},
  title = {"Kelly is a Warm Person, Joseph is a Role Model”: Gender Biases in LLM-Generated Reference Letters},
  journal = {arXiv preprint arXiv:2310.09219},
  year = {2023},
  url = {https://arxiv.org/pdf/2310.09219}
}
@misc{jiang2023mistral,
  author = {A. Q. Jiang and others},
  title = {Mistral 7B},
  year = {2023},
  howpublished = {\url{https://arxiv.org/abs/2310.06825}},
  note = {arXiv preprint arXiv:2310.06825},
  month = {Oct},
}
@article{li2024evaluating,
  author    = {M. Li and B. Krishnamachari},
  title     = {Evaluating ChatGPT-3.5 Efficiency in Solving Coding Problems of Different Complexity Levels: An Empirical Analysis},
  journal   = {arXiv preprint arXiv:2411.07529},
  year      = {2024},
  url       = {https://arxiv.org/pdf/2411.07529}
}
@misc{wang2024user,
  author = {Wang, Jiayin and Zhang, Zhi and Li, Xia},
  title = {User Intent and Satisfaction in LLM Interactions},
  year = {2024},
  eprint = {2401.08329},
  archivePrefix = {arXiv},
  primaryClass = {cs.HC},
  note = {Accessed: 27-Apr-2025},
  url = {https://arxiv.org/pdf/2401.08329}
}
@misc{HaluEval2024,
  author       = {RUCAIBox},
  title        = {{HaluEval}},
  year         = {2024},
  howpublished = {\url{https://github.com/RUCAIBox/HaluEval}},
  note         = {Accessed: 2025-05-07}
}
@article{ji2024pkusaferlhf,
  title={PKU-SafeRLHF: Towards Multi-Level Safety Alignment for LLMs with Human Preference},
  author={Ji, Jiaming and Hong, Donghai and Zhang, Borong and Chen, Boyuan and Dai, Josef and Zheng, Boren and Qiu, Tianyi and Li, Boxun and Yang, Yaodong},
  journal={arXiv preprint arXiv:2406.15513},
  year={2024},
  url={https://arxiv.org/abs/2406.15513}
}

@article{schulman2017ppo,
  title={Proximal Policy Optimization Algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017},
  url={https://arxiv.org/abs/1707.06347}
}
@inproceedings{wolf-etal-2020-transformers,
  title = {Transformers: State-of-the-Art Natural Language Processing},
  author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Rémi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages = {38--45},
  year = {2020},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2020.emnlp-demos.6/},
  doi = {10.18653/v1/2020.emnlp-demos.6}
}
@misc{han2024parameter,
  title        = {Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey},
  author       = {Zeyu Han and Chao Gao and Jinyang Liu and Jeff Zhang and Sai Qian Zhang},
  year         = {2024},
  month        = {March},
  eprint       = {2403.14608},
  archivePrefix= {arXiv},
  primaryClass = {cs.LG},
  note         = {arXiv preprint},
  url          = {https://arxiv.org/abs/2403.14608}
}